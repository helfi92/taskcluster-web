{
  "$schema": "/schemas/common/api-reference-v0.json#",
  "title": "Queue API Documentation",
  "description": "The queue service is responsible for accepting tasks and track their state\nas they are executed by workers. In order ensure they are eventually\nresolved.\n\nThis document describes the API end-points offered by the queue. These \nend-points targets the following audience:\n * Schedulers, who create tasks to be executed,\n * Workers, who execute tasks, and\n * Tools, that wants to inspect the state of a task.",
  "serviceName": "queue",
  "apiVersion": "v1",
  "entries": [
    {
      "type": "function",
      "method": "get",
      "route": "/ping",
      "query": [],
      "args": [],
      "name": "ping",
      "stability": "stable",
      "title": "Ping Server",
      "description": "Respond without doing anything.\nThis endpoint is used to check that the service is up."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/task/<taskId>",
      "query": [],
      "args": [
        "taskId"
      ],
      "name": "task",
      "stability": "stable",
      "title": "Get Task Definition",
      "output": "v1/task.json#",
      "description": "This end-point will return the task-definition. Notice that the task\ndefinition may have been modified by queue, if an optional property is\nnot specified the queue may provide a default value."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/task/<taskId>/status",
      "query": [],
      "args": [
        "taskId"
      ],
      "name": "status",
      "stability": "stable",
      "title": "Get task status",
      "output": "v1/task-status-response.json#",
      "description": "Get task status structure from `taskId`"
    },
    {
      "type": "function",
      "method": "get",
      "route": "/task-group/<taskGroupId>/list",
      "query": [
        "continuationToken",
        "limit"
      ],
      "args": [
        "taskGroupId"
      ],
      "name": "listTaskGroup",
      "stability": "stable",
      "title": "List Task Group",
      "output": "v1/list-task-group-response.json#",
      "description": "List tasks sharing the same `taskGroupId`.\n\nAs a task-group may contain an unbounded number of tasks, this end-point\nmay return a `continuationToken`. To continue listing tasks you must call\nthe `listTaskGroup` again with the `continuationToken` as the\nquery-string option `continuationToken`.\n\nBy default this end-point will try to return up to 1000 members in one\nrequest. But it **may return less**, even if more tasks are available.\nIt may also return a `continuationToken` even though there are no more\nresults. However, you can only be sure to have seen all results if you\nkeep calling `listTaskGroup` with the last `continuationToken` until you\nget a result without a `continuationToken`.\n\nIf you are not interested in listing all the members at once, you may\nuse the query-string option `limit` to return fewer."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/task/<taskId>/dependents",
      "query": [
        "continuationToken",
        "limit"
      ],
      "args": [
        "taskId"
      ],
      "name": "listDependentTasks",
      "stability": "stable",
      "title": "List Dependent Tasks",
      "output": "v1/list-dependent-tasks-response.json#",
      "description": "List tasks that depend on the given `taskId`.\n\nAs many tasks from different task-groups may dependent on a single tasks,\nthis end-point may return a `continuationToken`. To continue listing\ntasks you must call `listDependentTasks` again with the\n`continuationToken` as the query-string option `continuationToken`.\n\nBy default this end-point will try to return up to 1000 tasks in one\nrequest. But it **may return less**, even if more tasks are available.\nIt may also return a `continuationToken` even though there are no more\nresults. However, you can only be sure to have seen all results if you\nkeep calling `listDependentTasks` with the last `continuationToken` until\nyou get a result without a `continuationToken`.\n\nIf you are not interested in listing all the tasks at once, you may\nuse the query-string option `limit` to return fewer."
    },
    {
      "type": "function",
      "method": "put",
      "route": "/task/<taskId>",
      "query": [],
      "args": [
        "taskId"
      ],
      "name": "createTask",
      "stability": "stable",
      "title": "Create New Task",
      "input": "v1/create-task-request.json#",
      "output": "v1/task-status-response.json#",
      "description": "Create a new task, this is an **idempotent** operation, so repeat it if\nyou get an internal server error or network connection is dropped.\n\n**Task `deadline`**: the deadline property can be no more than 5 days\ninto the future. This is to limit the amount of pending tasks not being\ntaken care of. Ideally, you should use a much shorter deadline.\n\n**Task expiration**: the `expires` property must be greater than the\ntask `deadline`. If not provided it will default to `deadline` + one\nyear. Notice, that artifacts created by task must expire before the task.\n\n**Task specific routing-keys**: using the `task.routes` property you may\ndefine task specific routing-keys. If a task has a task specific \nrouting-key: `<route>`, then when the AMQP message about the task is\npublished, the message will be CC'ed with the routing-key: \n`route.<route>`. This is useful if you want another component to listen\nfor completed tasks you have posted.  The caller must have scope\n`queue:route:<route>` for each route.\n\n**Dependencies**: any tasks referenced in `task.dependencies` must have\nalready been created at the time of this call.\n\n**Scopes**: Note that the scopes required to complete this API call depend\non the content of the `scopes`, `routes`, `schedulerId`, `priority`,\n`provisionerId`, and `workerType` properties of the task definition.\n\n**Legacy Scopes**: The `queue:create-task:..` scope without a priority and\nthe `queue:define-task:..` and `queue:task-group-id:..` scopes are considered\nlegacy and should not be used. Note that the new, non-legacy scopes require\na `queue:scheduler-id:..` scope as well as scopes for the proper priority.",
      "scopes": {
        "AllOf": [
          {
            "for": "scope",
            "in": "scopes",
            "each": "<scope>"
          },
          {
            "for": "route",
            "in": "routes",
            "each": "queue:route:<route>"
          },
          {
            "AnyOf": [
              {
                "AllOf": [
                  "queue:scheduler-id:<schedulerId>",
                  {
                    "AnyOf": [
                      {
                        "for": "priority",
                        "in": "priorities",
                        "each": "queue:create-task:<priority>:<provisionerId>/<workerType>"
                      }
                    ]
                  }
                ]
              },
              {
                "if": "legacyScopes",
                "then": {
                  "AnyOf": [
                    "queue:create-task:<provisionerId>/<workerType>",
                    {
                      "AllOf": [
                        "queue:define-task:<provisionerId>/<workerType>",
                        "queue:task-group-id:<schedulerId>/<taskGroupId>",
                        "queue:schedule-task:<schedulerId>/<taskGroupId>/<taskId>"
                      ]
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/define",
      "query": [],
      "args": [
        "taskId"
      ],
      "name": "defineTask",
      "stability": "deprecated",
      "title": "Define Task",
      "input": "v1/create-task-request.json#",
      "output": "v1/task-status-response.json#",
      "description": "**Deprecated**, this is the same as `createTask` with a **self-dependency**.\nThis is only present for legacy.",
      "scopes": {
        "AllOf": [
          {
            "for": "scope",
            "in": "scopes",
            "each": "<scope>"
          },
          {
            "for": "route",
            "in": "routes",
            "each": "queue:route:<route>"
          },
          {
            "AnyOf": [
              {
                "AllOf": [
                  "queue:scheduler-id:<schedulerId>",
                  {
                    "AnyOf": [
                      {
                        "for": "priority",
                        "in": "priorities",
                        "each": "queue:create-task:<priority>:<provisionerId>/<workerType>"
                      }
                    ]
                  }
                ]
              },
              {
                "if": "legacyScopes",
                "then": {
                  "AnyOf": [
                    "queue:define-task:<provisionerId>/<workerType>",
                    "queue:create-task:<provisionerId>/<workerType>",
                    {
                      "AllOf": [
                        "queue:define-task:<provisionerId>/<workerType>",
                        "queue:task-group-id:<schedulerId>/<taskGroupId>"
                      ]
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/schedule",
      "query": [],
      "args": [
        "taskId"
      ],
      "name": "scheduleTask",
      "stability": "stable",
      "title": "Schedule Defined Task",
      "output": "v1/task-status-response.json#",
      "description": "scheduleTask will schedule a task to be executed, even if it has\nunresolved dependencies. A task would otherwise only be scheduled if\nits dependencies were resolved.\n\nThis is useful if you have defined a task that depends on itself or on\nsome other task that has not been resolved, but you wish the task to be\nscheduled immediately.\n\nThis will announce the task as pending and workers will be allowed to\nclaim it and resolve the task.\n\n**Note** this operation is **idempotent** and will not fail or complain\nif called with a `taskId` that is already scheduled, or even resolved.\nTo reschedule a task previously resolved, use `rerunTask`.",
      "scopes": {
        "AnyOf": [
          "queue:schedule-task:<schedulerId>/<taskGroupId>/<taskId>",
          {
            "AllOf": [
              "queue:schedule-task",
              "assume:scheduler-id:<schedulerId>/<taskGroupId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/rerun",
      "query": [],
      "args": [
        "taskId"
      ],
      "name": "rerunTask",
      "stability": "deprecated",
      "title": "Rerun a Resolved Task",
      "output": "v1/task-status-response.json#",
      "description": "This method _reruns_ a previously resolved task, even if it was\n_completed_. This is useful if your task completes unsuccessfully, and\nyou just want to run it from scratch again. This will also reset the\nnumber of `retries` allowed.\n\nThis method is deprecated in favour of creating a new task with the same\ntask definition (but with a new taskId).\n\nRemember that `retries` in the task status counts the number of runs that\nthe queue have started because the worker stopped responding, for example\nbecause a spot node died.\n\n**Remark** this operation is idempotent, if you try to rerun a task that\nis not either `failed` or `completed`, this operation will just return\nthe current task status.",
      "scopes": {
        "AnyOf": [
          "queue:rerun-task:<schedulerId>/<taskGroupId>/<taskId>",
          {
            "AllOf": [
              "queue:rerun-task",
              "assume:scheduler-id:<schedulerId>/<taskGroupId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/cancel",
      "query": [],
      "args": [
        "taskId"
      ],
      "name": "cancelTask",
      "stability": "stable",
      "title": "Cancel Task",
      "output": "v1/task-status-response.json#",
      "description": "This method will cancel a task that is either `unscheduled`, `pending` or\n`running`. It will resolve the current run as `exception` with\n`reasonResolved` set to `canceled`. If the task isn't scheduled yet, ie.\nit doesn't have any runs, an initial run will be added and resolved as\ndescribed above. Hence, after canceling a task, it cannot be scheduled\nwith `queue.scheduleTask`, but a new run can be created with\n`queue.rerun`. These semantics is equivalent to calling\n`queue.scheduleTask` immediately followed by `queue.cancelTask`.\n\n**Remark** this operation is idempotent, if you try to cancel a task that\nisn't `unscheduled`, `pending` or `running`, this operation will just\nreturn the current task status.",
      "scopes": {
        "AnyOf": [
          "queue:cancel-task:<schedulerId>/<taskGroupId>/<taskId>",
          {
            "AllOf": [
              "queue:cancel-task",
              "assume:scheduler-id:<schedulerId>/<taskGroupId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/claim-work/<provisionerId>/<workerType>",
      "query": [],
      "args": [
        "provisionerId",
        "workerType"
      ],
      "name": "claimWork",
      "stability": "stable",
      "title": "Claim Work",
      "input": "v1/claim-work-request.json#",
      "output": "v1/claim-work-response.json#",
      "description": "Claim pending task(s) for the given `provisionerId`/`workerType` queue.\n\nIf any work is available (even if fewer than the requested number of\ntasks, this will return immediately. Otherwise, it will block for tens of\nseconds waiting for work.  If no work appears, it will return an emtpy\nlist of tasks.  Callers should sleep a short while (to avoid denial of\nservice in an error condition) and call the endpoint again.  This is a\nsimple implementation of \"long polling\".",
      "scopes": {
        "AllOf": [
          "queue:claim-work:<provisionerId>/<workerType>",
          "queue:worker-id:<workerGroup>/<workerId>"
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/runs/<runId>/claim",
      "query": [],
      "args": [
        "taskId",
        "runId"
      ],
      "name": "claimTask",
      "stability": "deprecated",
      "title": "Claim Task",
      "input": "v1/task-claim-request.json#",
      "output": "v1/task-claim-response.json#",
      "description": "claim a task - never documented",
      "scopes": {
        "AnyOf": [
          {
            "AllOf": [
              "queue:claim-task:<provisionerId>/<workerType>",
              "queue:worker-id:<workerGroup>/<workerId>"
            ]
          },
          {
            "AllOf": [
              "queue:claim-task",
              "assume:worker-type:<provisionerId>/<workerType>",
              "assume:worker-id:<workerGroup>/<workerId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/runs/<runId>/reclaim",
      "query": [],
      "args": [
        "taskId",
        "runId"
      ],
      "name": "reclaimTask",
      "stability": "stable",
      "title": "Reclaim task",
      "output": "v1/task-reclaim-response.json#",
      "description": "Refresh the claim for a specific `runId` for given `taskId`. This updates\nthe `takenUntil` property and returns a new set of temporary credentials\nfor performing requests on behalf of the task. These credentials should\nbe used in-place of the credentials returned by `claimWork`.\n\nThe `reclaimTask` requests serves to:\n * Postpone `takenUntil` preventing the queue from resolving\n   `claim-expired`,\n * Refresh temporary credentials used for processing the task, and\n * Abort execution if the task/run have been resolved.\n\nIf the `takenUntil` timestamp is exceeded the queue will resolve the run\nas _exception_ with reason `claim-expired`, and proceeded to retry to the\ntask. This ensures that tasks are retried, even if workers disappear\nwithout warning.\n\nIf the task is resolved, this end-point will return `409` reporting\n`RequestConflict`. This typically happens if the task have been canceled\nor the `task.deadline` have been exceeded. If reclaiming fails, workers\nshould abort the task and forget about the given `runId`. There is no\nneed to resolve the run or upload artifacts.",
      "scopes": {
        "AnyOf": [
          "queue:reclaim-task:<taskId>/<runId>",
          {
            "AllOf": [
              "queue:claim-task",
              "assume:worker-id:<workerGroup>/<workerId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/runs/<runId>/completed",
      "query": [],
      "args": [
        "taskId",
        "runId"
      ],
      "name": "reportCompleted",
      "stability": "stable",
      "title": "Report Run Completed",
      "output": "v1/task-status-response.json#",
      "description": "Report a task completed, resolving the run as `completed`.",
      "scopes": {
        "AnyOf": [
          "queue:resolve-task:<taskId>/<runId>",
          {
            "AllOf": [
              "queue:resolve-task",
              "assume:worker-id:<workerGroup>/<workerId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/runs/<runId>/failed",
      "query": [],
      "args": [
        "taskId",
        "runId"
      ],
      "name": "reportFailed",
      "stability": "stable",
      "title": "Report Run Failed",
      "output": "v1/task-status-response.json#",
      "description": "Report a run failed, resolving the run as `failed`. Use this to resolve\na run that failed because the task specific code behaved unexpectedly.\nFor example the task exited non-zero, or didn't produce expected output.\n\nDo not use this if the task couldn't be run because if malformed\npayload, or other unexpected condition. In these cases we have a task\nexception, which should be reported with `reportException`.",
      "scopes": {
        "AnyOf": [
          "queue:resolve-task:<taskId>/<runId>",
          {
            "AllOf": [
              "queue:resolve-task",
              "assume:worker-id:<workerGroup>/<workerId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/runs/<runId>/exception",
      "query": [],
      "args": [
        "taskId",
        "runId"
      ],
      "name": "reportException",
      "stability": "stable",
      "title": "Report Task Exception",
      "input": "v1/task-exception-request.json#",
      "output": "v1/task-status-response.json#",
      "description": "Resolve a run as _exception_. Generally, you will want to report tasks as\nfailed instead of exception. You should `reportException` if,\n\n  * The `task.payload` is invalid,\n  * Non-existent resources are referenced,\n  * Declared actions cannot be executed due to unavailable resources,\n  * The worker had to shutdown prematurely,\n  * The worker experienced an unknown error, or,\n  * The task explicitly requested a retry.\n\nDo not use this to signal that some user-specified code crashed for any\nreason specific to this code. If user-specific code hits a resource that\nis temporarily unavailable worker should report task _failed_.",
      "scopes": {
        "AnyOf": [
          "queue:resolve-task:<taskId>/<runId>",
          {
            "AllOf": [
              "queue:resolve-task",
              "assume:worker-id:<workerGroup>/<workerId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "post",
      "route": "/task/<taskId>/runs/<runId>/artifacts/<name>",
      "query": [],
      "args": [
        "taskId",
        "runId",
        "name"
      ],
      "name": "createArtifact",
      "stability": "stable",
      "title": "Create Artifact",
      "input": "v1/post-artifact-request.json#",
      "output": "v1/post-artifact-response.json#",
      "description": "This API end-point creates an artifact for a specific run of a task. This\nshould **only** be used by a worker currently operating on this task, or\nfrom a process running within the task (ie. on the worker).\n\nAll artifacts must specify when they `expires`, the queue will\nautomatically take care of deleting artifacts past their\nexpiration point. This features makes it feasible to upload large\nintermediate artifacts from data processing applications, as the\nartifacts can be set to expire a few days later.\n\nWe currently support 3 different `storageType`s, each storage type have\nslightly different features and in some cases difference semantics.\nWe also have 2 deprecated `storageType`s which are only maintained for\nbackwards compatiability and should not be used in new implementations\n\n**Blob artifacts**, are useful for storing large files.  Currently, these\nare all stored in S3 but there are facilities for adding support for other\nbackends in futre.  A call for this type of artifact must provide information\nabout the file which will be uploaded.  This includes sha256 sums and sizes.\nThis method will return a list of general form HTTP requests which are signed\nby AWS S3 credentials managed by the Queue.  Once these requests are completed\nthe list of `ETag` values returned by the requests must be passed to the\nqueue `completeArtifact` method\n\n**S3 artifacts**, DEPRECATED is useful for static files which will be\nstored on S3. When creating an S3 artifact the queue will return a\npre-signed URL to which you can do a `PUT` request to upload your\nartifact. Note that `PUT` request **must** specify the `content-length`\nheader and **must** give the `content-type` header the same value as in\nthe request to `createArtifact`.\n\n**Azure artifacts**, DEPRECATED are stored in _Azure Blob Storage_ service\nwhich given the consistency guarantees and API interface offered by Azure\nis more suitable for artifacts that will be modified during the execution\nof the task. For example docker-worker has a feature that persists the\ntask log to Azure Blob Storage every few seconds creating a somewhat\nlive log. A request to create an Azure artifact will return a URL\nfeaturing a [Shared-Access-Signature](http://msdn.microsoft.com/en-us/library/azure/dn140256.aspx),\nrefer to MSDN for further information on how to use these.\n**Warning: azure artifact is currently an experimental feature subject\nto changes and data-drops.**\n\n**Reference artifacts**, only consists of meta-data which the queue will\nstore for you. These artifacts really only have a `url` property and\nwhen the artifact is requested the client will be redirect the URL\nprovided with a `303` (See Other) redirect. Please note that we cannot\ndelete artifacts you upload to other service, we can only delete the\nreference to the artifact, when it expires.\n\n**Error artifacts**, only consists of meta-data which the queue will\nstore for you. These artifacts are only meant to indicate that you the\nworker or the task failed to generate a specific artifact, that you\nwould otherwise have uploaded. For example docker-worker will upload an\nerror artifact, if the file it was supposed to upload doesn't exists or\nturns out to be a directory. Clients requesting an error artifact will\nget a `424` (Failed Dependency) response. This is mainly designed to\nensure that dependent tasks can distinguish between artifacts that were\nsuppose to be generated and artifacts for which the name is misspelled.\n\n**Artifact immutability**, generally speaking you cannot overwrite an\nartifact when created. But if you repeat the request with the same\nproperties the request will succeed as the operation is idempotent.\nThis is useful if you need to refresh a signed URL while uploading.\nDo not abuse this to overwrite artifacts created by another entity!\nSuch as worker-host overwriting artifact created by worker-code.\n\nAs a special case the `url` property on _reference artifacts_ can be\nupdated. You should only use this to update the `url` property for\nreference artifacts your process has created.",
      "scopes": {
        "AnyOf": [
          "queue:create-artifact:<taskId>/<runId>",
          {
            "AllOf": [
              "queue:create-artifact:<name>",
              "assume:worker-id:<workerGroup>/<workerId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "put",
      "route": "/task/<taskId>/runs/<runId>/artifacts/<name>",
      "query": [],
      "args": [
        "taskId",
        "runId",
        "name"
      ],
      "name": "completeArtifact",
      "stability": "experimental",
      "title": "Complete Artifact",
      "input": "v1/put-artifact-request.json#",
      "description": "This endpoint finalises an upload done through the blob `storageType`.\nThe queue will ensure that the task/run is still allowing artifacts\nto be uploaded.  For single-part S3 blob artifacts, this endpoint\nwill simply ensure the artifact is present in S3.  For multipart S3\nartifacts, the endpoint will perform the commit step of the multipart\nupload flow.  As the final step for both multi and single part artifacts,\nthe `present` entity field will be set to `true` to reflect that the\nartifact is now present and a message published to pulse.  NOTE: This\nendpoint *must* be called for all artifacts of storageType 'blob'",
      "scopes": {
        "AnyOf": [
          "queue:create-artifact:<taskId>/<runId>",
          {
            "AllOf": [
              "queue:create-artifact:<name>",
              "assume:worker-id:<workerGroup>/<workerId>"
            ]
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "get",
      "route": "/task/<taskId>/runs/<runId>/artifacts/<name>",
      "query": [],
      "args": [
        "taskId",
        "runId",
        "name"
      ],
      "name": "getArtifact",
      "stability": "stable",
      "title": "Get Artifact from Run",
      "description": "Get artifact by `<name>` from a specific run.\n\n**Public Artifacts**, in-order to get an artifact you need the scope\n`queue:get-artifact:<name>`, where `<name>` is the name of the artifact.\nBut if the artifact `name` starts with `public/`, authentication and\nauthorization is not necessary to fetch the artifact.\n\n**API Clients**, this method will redirect you to the artifact, if it is\nstored externally. Either way, the response may not be JSON. So API\nclient users might want to generate a signed URL for this end-point and\nuse that URL with an HTTP client that can handle responses correctly.\n\n**Downloading artifacts**\nThere are some special considerations for those http clients which download\nartifacts.  This api endpoint is designed to be compatible with an HTTP 1.1\ncompliant client, but has extra features to ensure the download is valid.\nIt is strongly recommend that consumers use either taskcluster-lib-artifact (JS),\ntaskcluster-lib-artifact-go (Go) or the CLI written in Go to interact with\nartifacts.\n\nIn order to download an artifact the following must be done:\n\n1. Obtain queue url.  Building a signed url with a taskcluster client is\nrecommended\n1. Make a GET request which does not follow redirects\n1. In all cases, if specified, the\nx-taskcluster-location-{content,transfer}-{sha256,length} values must be\nvalidated to be equal to the Content-Length and Sha256 checksum of the\nfinal artifact downloaded. as well as any intermediate redirects\n1. If this response is a 500-series error, retry using an exponential\nbackoff.  No more than 5 retries should be attempted\n1. If this response is a 400-series error, treat it appropriately for\nyour context.  This might be an error in responding to this request or\nan Error storage type body.  This request should not be retried.\n1. If this response is a 200-series response, the response body is the artifact.\nIf the x-taskcluster-location-{content,transfer}-{sha256,length} and\nx-taskcluster-location-content-encoding are specified, they should match\nthis response body\n1. If the response type is a 300-series redirect, the artifact will be at the\nlocation specified by the `Location` header.  There are multiple artifact storage\ntypes which use a 300-series redirect.\n1. For all redirects followed, the user must verify that the content-sha256, content-length,\ntransfer-sha256, transfer-length and content-encoding match every further request.  The final\nartifact must also be validated against the values specified in the original queue response\n1. Caching of requests with an x-taskcluster-artifact-storage-type value of `reference`\nmust not occur\n1. A request which has x-taskcluster-artifact-storage-type value of `blob` and does not\nhave x-taskcluster-location-content-sha256 or x-taskcluster-location-content-length\nmust be treated as an error\n\n**Headers**\nThe following important headers are set on the response to this method:\n\n* location: the url of the artifact if a redirect is to be performed\n* x-taskcluster-artifact-storage-type: the storage type.  Example: blob, s3, error\n\nThe following important headers are set on responses to this method for Blob artifacts\n\n* x-taskcluster-location-content-sha256: the SHA256 of the artifact\n*after* any content-encoding is undone.  Sha256 is hex encoded (e.g. [0-9A-Fa-f]{64})\n* x-taskcluster-location-content-length: the number of bytes *after* any content-encoding\nis undone\n* x-taskcluster-location-transfer-sha256: the SHA256 of the artifact\n*before* any content-encoding is undone.  This is the SHA256 of what is sent over\nthe wire.  Sha256 is hex encoded (e.g. [0-9A-Fa-f]{64})\n* x-taskcluster-location-transfer-length: the number of bytes *after* any content-encoding\nis undone\n* x-taskcluster-location-content-encoding: the content-encoding used.  It will either\nbe `gzip` or `identity` right now.  This is hardcoded to a value set when the artifact\nwas created and no content-negotiation occurs\n* x-taskcluster-location-content-type: the content-type of the artifact\n\n**Caching**, artifacts may be cached in data centers closer to the\nworkers in-order to reduce bandwidth costs. This can lead to longer\nresponse times. Caching can be skipped by setting the header\n`x-taskcluster-skip-cache: true`, this should only be used for resources\nwhere request volume is known to be low, and caching not useful.\n(This feature may be disabled in the future, use is sparingly!)",
      "scopes": {
        "if": "private",
        "then": {
          "AllOf": [
            "queue:get-artifact:<name>"
          ]
        }
      }
    },
    {
      "type": "function",
      "method": "get",
      "route": "/task/<taskId>/artifacts/<name>",
      "query": [],
      "args": [
        "taskId",
        "name"
      ],
      "name": "getLatestArtifact",
      "stability": "stable",
      "title": "Get Artifact from Latest Run",
      "description": "Get artifact by `<name>` from the last run of a task.\n\n**Public Artifacts**, in-order to get an artifact you need the scope\n`queue:get-artifact:<name>`, where `<name>` is the name of the artifact.\nBut if the artifact `name` starts with `public/`, authentication and\nauthorization is not necessary to fetch the artifact.\n\n**API Clients**, this method will redirect you to the artifact, if it is\nstored externally. Either way, the response may not be JSON. So API\nclient users might want to generate a signed URL for this end-point and\nuse that URL with a normal HTTP client.\n\n**Remark**, this end-point is slightly slower than\n`queue.getArtifact`, so consider that if you already know the `runId` of\nthe latest run. Otherwise, just us the most convenient API end-point.",
      "scopes": {
        "if": "private",
        "then": {
          "AllOf": [
            "queue:get-artifact:<name>"
          ]
        }
      }
    },
    {
      "type": "function",
      "method": "get",
      "route": "/task/<taskId>/runs/<runId>/artifacts",
      "query": [
        "continuationToken",
        "limit"
      ],
      "args": [
        "taskId",
        "runId"
      ],
      "name": "listArtifacts",
      "stability": "experimental",
      "title": "Get Artifacts from Run",
      "output": "v1/list-artifacts-response.json#",
      "description": "Returns a list of artifacts and associated meta-data for a given run.\n\nAs a task may have many artifacts paging may be necessary. If this\nend-point returns a `continuationToken`, you should call the end-point\nagain with the `continuationToken` as the query-string option:\n`continuationToken`.\n\nBy default this end-point will list up-to 1000 artifacts in a single page\nyou may limit this with the query-string parameter `limit`."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/task/<taskId>/artifacts",
      "query": [
        "continuationToken",
        "limit"
      ],
      "args": [
        "taskId"
      ],
      "name": "listLatestArtifacts",
      "stability": "experimental",
      "title": "Get Artifacts from Latest Run",
      "output": "v1/list-artifacts-response.json#",
      "description": "Returns a list of artifacts and associated meta-data for the latest run\nfrom the given task.\n\nAs a task may have many artifacts paging may be necessary. If this\nend-point returns a `continuationToken`, you should call the end-point\nagain with the `continuationToken` as the query-string option:\n`continuationToken`.\n\nBy default this end-point will list up-to 1000 artifacts in a single page\nyou may limit this with the query-string parameter `limit`."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/provisioners",
      "query": [
        "continuationToken",
        "limit"
      ],
      "args": [],
      "name": "listProvisioners",
      "stability": "experimental",
      "title": "Get a list of all active provisioners",
      "output": "v1/list-provisioners-response.json#",
      "description": "Get all active provisioners.\n\nThe term \"provisioner\" is taken broadly to mean anything with a provisionerId.\nThis does not necessarily mean there is an associated service performing any\nprovisioning activity.\n\nThe response is paged. If this end-point returns a `continuationToken`, you\nshould call the end-point again with the `continuationToken` as a query-string\noption. By default this end-point will list up to 1000 provisioners in a single\npage. You may limit this with the query-string parameter `limit`."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/provisioners/<provisionerId>",
      "query": [],
      "args": [
        "provisionerId"
      ],
      "name": "getProvisioner",
      "stability": "experimental",
      "title": "Get an active provisioner",
      "output": "v1/provisioner-response.json#",
      "description": "Get an active provisioner.\n\nThe term \"provisioner\" is taken broadly to mean anything with a provisionerId.\nThis does not necessarily mean there is an associated service performing any\nprovisioning activity."
    },
    {
      "type": "function",
      "method": "put",
      "route": "/provisioners/<provisionerId>",
      "query": [],
      "args": [
        "provisionerId"
      ],
      "name": "declareProvisioner",
      "stability": "experimental",
      "title": "Update a provisioner",
      "input": "v1/update-provisioner-request.json#",
      "output": "v1/provisioner-response.json#",
      "description": "Declare a provisioner, supplying some details about it.\n\n`declareProvisioner` allows updating one or more properties of a provisioner as long as the required scopes are\npossessed. For example, a request to update the `aws-provisioner-v1`\nprovisioner with a body `{description: 'This provisioner is great'}` would require you to have the scope\n`queue:declare-provisioner:aws-provisioner-v1#description`.\n\nThe term \"provisioner\" is taken broadly to mean anything with a provisionerId.\nThis does not necessarily mean there is an associated service performing any\nprovisioning activity.",
      "scopes": {
        "AllOf": [
          {
            "for": "property",
            "in": "properties",
            "each": "queue:declare-provisioner:<provisionerId>#<property>"
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "get",
      "route": "/pending/<provisionerId>/<workerType>",
      "query": [],
      "args": [
        "provisionerId",
        "workerType"
      ],
      "name": "pendingTasks",
      "stability": "stable",
      "title": "Get Number of Pending Tasks",
      "output": "v1/pending-tasks-response.json#",
      "description": "Get an approximate number of pending tasks for the given `provisionerId`\nand `workerType`.\n\nThe underlying Azure Storage Queues only promises to give us an estimate.\nFurthermore, we cache the result in memory for 20 seconds. So consumers\nshould be no means expect this to be an accurate number.\nIt is, however, a solid estimate of the number of pending tasks."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/provisioners/<provisionerId>/worker-types",
      "query": [
        "continuationToken",
        "limit"
      ],
      "args": [
        "provisionerId"
      ],
      "name": "listWorkerTypes",
      "stability": "experimental",
      "title": "Get a list of all active worker-types",
      "output": "v1/list-workertypes-response.json#",
      "description": "Get all active worker-types for the given provisioner.\n\nThe response is paged. If this end-point returns a `continuationToken`, you\nshould call the end-point again with the `continuationToken` as a query-string\noption. By default this end-point will list up to 1000 worker-types in a single\npage. You may limit this with the query-string parameter `limit`."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/provisioners/<provisionerId>/worker-types/<workerType>",
      "query": [],
      "args": [
        "provisionerId",
        "workerType"
      ],
      "name": "getWorkerType",
      "stability": "experimental",
      "title": "Get a worker-type",
      "output": "v1/workertype-response.json#",
      "description": "Get a worker-type from a provisioner."
    },
    {
      "type": "function",
      "method": "put",
      "route": "/provisioners/<provisionerId>/worker-types/<workerType>",
      "query": [],
      "args": [
        "provisionerId",
        "workerType"
      ],
      "name": "declareWorkerType",
      "stability": "experimental",
      "title": "Update a worker-type",
      "input": "v1/update-workertype-request.json#",
      "output": "v1/workertype-response.json#",
      "description": "Declare a workerType, supplying some details about it.\n\n`declareWorkerType` allows updating one or more properties of a worker-type as long as the required scopes are\npossessed. For example, a request to update the `gecko-b-1-w2008` worker-type within the `aws-provisioner-v1`\nprovisioner with a body `{description: 'This worker type is great'}` would require you to have the scope\n`queue:declare-worker-type:aws-provisioner-v1/gecko-b-1-w2008#description`.",
      "scopes": {
        "AllOf": [
          {
            "for": "property",
            "in": "properties",
            "each": "queue:declare-worker-type:<provisionerId>/<workerType>#<property>"
          }
        ]
      }
    },
    {
      "type": "function",
      "method": "get",
      "route": "/provisioners/<provisionerId>/worker-types/<workerType>/workers",
      "query": [
        "continuationToken",
        "limit",
        "quarantined"
      ],
      "args": [
        "provisionerId",
        "workerType"
      ],
      "name": "listWorkers",
      "stability": "experimental",
      "title": "Get a list of all active workers of a workerType",
      "output": "v1/list-workers-response.json#",
      "description": "Get a list of all active workers of a workerType.\n\n`listWorkers` allows a response to be filtered by quarantined and non quarantined workers.\nTo filter the query, you should call the end-point with `quarantined` as a query-string option with a\ntrue or false value.\n\nThe response is paged. If this end-point returns a `continuationToken`, you\nshould call the end-point again with the `continuationToken` as a query-string\noption. By default this end-point will list up to 1000 workers in a single\npage. You may limit this with the query-string parameter `limit`."
    },
    {
      "type": "function",
      "method": "get",
      "route": "/provisioners/<provisionerId>/worker-types/<workerType>/workers/<workerGroup>/<workerId>",
      "query": [],
      "args": [
        "provisionerId",
        "workerType",
        "workerGroup",
        "workerId"
      ],
      "name": "getWorker",
      "stability": "experimental",
      "title": "Get a worker-type",
      "output": "v1/worker-response.json#",
      "description": "Get a worker from a worker-type."
    },
    {
      "type": "function",
      "method": "put",
      "route": "/provisioners/<provisionerId>/worker-types/<workerType>/workers/<workerGroup>/<workerId>",
      "query": [],
      "args": [
        "provisionerId",
        "workerType",
        "workerGroup",
        "workerId"
      ],
      "name": "quarantineWorker",
      "stability": "experimental",
      "title": "Quarantine a worker",
      "input": "v1/quarantine-worker-request.json#",
      "output": "v1/worker-response.json#",
      "description": "Quarantine a worker",
      "scopes": {
        "AllOf": [
          "queue:quarantine-worker:<provisionerId>/<workerType>/<workerGroup>/<workerId>"
        ]
      }
    },
    {
      "type": "function",
      "method": "put",
      "route": "/provisioners/<provisionerId>/worker-types/<workerType>/<workerGroup>/<workerId>",
      "query": [],
      "args": [
        "provisionerId",
        "workerType",
        "workerGroup",
        "workerId"
      ],
      "name": "declareWorker",
      "stability": "experimental",
      "title": "Declare a worker",
      "input": "v1/update-worker-request.json#",
      "output": "v1/worker-response.json#",
      "description": "Declare a worker, supplying some details about it.\n\n`declareWorker` allows updating one or more properties of a worker as long as the required scopes are\npossessed.",
      "scopes": {
        "AllOf": [
          {
            "for": "property",
            "in": "properties",
            "each": "queue:declare-worker:<provisionerId>/<workerType>/<workerGroup>/<workerId>#<property>"
          }
        ]
      }
    }
  ]
}